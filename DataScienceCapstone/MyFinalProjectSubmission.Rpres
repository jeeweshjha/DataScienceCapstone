Course Project - Data Science Capstone Project: A Text Prediction Algorithm built with the SwiftKey Dataset
========================================================
author: Jeewesh Jha
date: 16 October 2017
autosize: true

Overview
========================================================

### Project Requirements
The goal of this exercise is to create a product to highlight the prediction algorithm that you have built and to provide an interface that can be accessed by others. For this project you must submit:

1. A Shiny app that takes as input a phrase (multiple words) in a text box input and outputs a prediction of the next word.
2. A slide deck consisting of no more than 5 slides created with R Studio Presenter pitching your algorithm and app as if you were presenting to your boss or an investor.


Calculating Probability Score
========================================================

The image below shows a conventional method for calculating the probability of a sentence. For our purposes the equation will be slightly different as we wish to predict the next word.


In order to predict the next word we begin with the left hand side of the equation below. This statement reads the probability of 'you' given 'looking forward seeing'. The full equation below employs a Markov assumption. Under this assumption we can reduce the computational complexity of algorithm.

Algorithm Rationale
========================================================

Key considerations for algorithm design:

- "A key point here is that the predictive model must be small enough to load onto the Shiny server. So pay attention to model size when creating and uploading your model." 

- "When you type a phrase in the input box do you get a prediction of a single word after pressing submit and/or a suitable delay for the model to compute the answer?"

Based on these requirements we chose a model based on existing NGrams. For a long piece of text we shorten the user input to the last three words and use the 4-gram table. These tables (1,2,3,4 gram) are loaded from a .txt file prior to execution of the algorithm. The file ‘createFilteredTables.R’ shows how the raw data files are transformed into N-Gram tables.

Repository Files
========================================================

The shiny app developed for this assignment is avalilable: https://jeeweshjha.shinyapps.io/datasciencecapstone/

The source codes of ui.R and server.R and also Rpresentation are available on the GitHub repo: https://github.com/jeeweshjha/DataScienceCapstone/

- createFilteredTables.R: this file takes the raw data and creates the file 'NGramSortedFinal.txt'
	+ this file uses the files in the 'functions' folder
- profanity.RData: a list of words to remove
- NGramSortedFinal.txt: contains four concatenated tables and the associated NGram counts
- divideNGram.RData: contains positions used to divide the table (from NGramSortedFinal.txt) into look up tables
	+ NGramSortedFinal.txt and divideNGram.RData are used to load and divide the tables used for searching for a match.
- getPredWord.R: this is the main function called by server.R for the application interface
	+ This file searches for matches based on the user input, implements "Stupid Backoff" if necessary, and calculates a penalty for the probability score
- global.R: loads the lookup tables to search for matches, loads additional libraries and functions
- server.R: code necessary to access user input, calls functions necessary to predict the next word, and return results to the user interface 
- ui.R: code necessary for the application interface
	